{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27298362",
   "metadata": {},
   "source": [
    "# (Purpose) Apply normalization procedure - FSQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a33a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- TCGA dataset ---------------------------              ** make sure input and outputs match!\n",
    "# ---------------------------- input file------------------------\n",
    "# filename_tcga = \"tcga_unscaled_unnormalized_nobatchcorrection__mockData.tsv\"  \n",
    "filename_tcga = \"tcga_unscaled_unnormalized_nobatchcorrection.tsv\"     # real data\n",
    "\n",
    "# ---------------------------- output file-----------------------\n",
    "save_filename_tcga = \"tcga_unscaled_fsqn_nobatchcorrection.tsv\"          # real data\n",
    "\n",
    "\n",
    "# ---------------------- GTEx dataset ---------------------------     \n",
    "# ---------------------------- input file------------------------\n",
    "# filename_gtex = \"gtex_unscaled_unnormalized_nobatchcorrection__mockData.tsv\"  \n",
    "filename_gtex = \"gtex_unscaled_unnormalized_nobatchcorrection.tsv\"     # real data\n",
    "\n",
    "# ---------------------------- output file-----------------------\n",
    "save_filename_gtex = \"gtex_unscaled_fsqn_nobatchcorrection.tsv\"          # real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3f646",
   "metadata": {},
   "source": [
    "## Install and load packages required in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "print(\"  begin -- installing R packages\")\n",
    "\n",
    "options(install.packages.compile.from.source = \"always\")\n",
    "install.packages(\"dplyr\", repos = getCRANmirrors()[1,\"URL\"])\n",
    "install.packages(\"readr\", repos = getCRANmirrors()[1,\"URL\"])\n",
    "install.packages(\"stringr\", repos = getCRANmirrors()[1,\"URL\"])\n",
    "install.packages(\"remotes\", repos = getCRANmirrors()[1,\"URL\"])\n",
    "if (!require(\"BiocManager\", quietly = TRUE))\n",
    "  install.packages(\"BiocManager\", repos = getCRANmirrors()[1,\"URL\"])\n",
    "BiocManager::install(\"preprocessCore\", configure.args = c(preprocessCore = \"--disable-threading\"), force= TRUE, update=TRUE, type = \"source\")\n",
    "remotes::install_github(\"jenniferfranks/FSQN\")\n",
    "\n",
    "print(\"  done  -- installing R packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fba239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "print(\"  begin -- loading packages\")\n",
    "\n",
    "library(dplyr)                  # a powerful and user-friendly package for data manipulation and transformation, \n",
    "                                #   providing a consistent and intuitive grammar to efficiently perform common data \n",
    "                                #   tasks on data frames and tibbles.  \n",
    "library(readr)                  # for reading and importing data from various file formats, offering fast and \n",
    "                                #   memory-efficient data import capabilities into R.\n",
    "library(stringr)                # for working with strings in R, offering a set of easy-to-use functions for string \n",
    "                                #   manipulation, pattern matching, and text extraction.\n",
    "library(data.table)             # extends data frames, providing enhanced functionality for handling large datasets, \n",
    "                                #   aggregation, joins, and more with concise syntax.\n",
    "library(preprocessCore)         # provides a collection of functions for preprocessing and normalizing microarray \n",
    "                                #   and RNA-Seq data, offering essential tools for quality control, \n",
    "                                #   background correction, and normalization to ensure accurate  \n",
    "                                #   and reliable downstream analyses.\n",
    "library(FSQN)                   # designed to quantile normalize each feature in a data set according to its \n",
    "                                #   corresponding feature in a target distribution. This eliminates distribution \n",
    "                                #   based differences resulting from the use of different gene expression \n",
    "                                #   profiling platforms.\n",
    "\n",
    "print(\"  done  -- loading packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- load table with readr package ----------\n",
    "filename_w_path_tcga = paste(\"data/preprocessing_combinations/\", filename_tcga, sep=\"\")\n",
    "filename_w_path_gtex = paste(\"data/preprocessing_combinations/\", filename_gtex, sep=\"\")\n",
    "\n",
    "# (remember) the # rows total does not include header row\n",
    "sprintf(\"  loading TCGA table -- %s\", filename_tcga)\n",
    "samples_tcga <- read_tsv(filename_w_path_tcga)\n",
    "print(\"  finished loading\")\n",
    "\n",
    "sprintf(\"  loading GTEx table -- %s\", filename_gtex)\n",
    "samples_gtex <- read_tsv(filename_w_path_gtex)\n",
    "print(\"  finished loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the top and bottom tcga table \n",
    "head(samples_tcga[,1:5], 2)\n",
    "tail(samples_tcga[,1:5], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3cc622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the top and bottom gtex table \n",
    "head(samples_gtex[,1:5], 2)\n",
    "tail(samples_gtex[,1:5], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684a311",
   "metadata": {},
   "source": [
    "## Split tcga into 80% train and 20% test\n",
    "\n",
    "- **note** the tcga dataset has already been randomly split and preserving class distribution in notebook08\n",
    "- here we split in the sense of taking the top 80% of file for train and bottom 20 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  [TCGA dataset already split] assigning the TCGA data into 80% train and 20% test sets\")  \n",
    "percent = 0.80\n",
    "\n",
    "samples_tcga_train <- head(samples_tcga, as.integer(nrow(samples_tcga)*percent) )\n",
    "samples_tcga_test <- anti_join(samples_tcga, samples_tcga_train, by = \"sample_id\" )\n",
    "\n",
    "print(\"  checking dimensions and tally of 80% TCGA for train set\")\n",
    "dim(samples_tcga_train)\n",
    "samples_tcga_train %>%\n",
    "      group_by(label) %>%\n",
    "      tally()\n",
    "\n",
    "print(\"  checking dimensions and tally of 20% TCGA for test set\")\n",
    "dim(samples_tcga_test)\n",
    "samples_tcga_test %>%\n",
    "      group_by(label) %>%\n",
    "      tally()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"previewing the top and bottom 80% tcga table\") \n",
    "print (head(samples_tcga_train[,1:5], 2) )\n",
    "print (tail(samples_tcga_train[,1:5], 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26334b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"previewing the top and bottom 20% tcga table\") \n",
    "print (head(samples_tcga_test[,1:5], 2) )\n",
    "print (tail(samples_tcga_test[,1:5], 2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94078997",
   "metadata": {},
   "source": [
    "## Apply normalization (here is Feature Specific Quantile Normalization) on the following:\n",
    "- 100% GTEx for test set #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aaf84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare function that will be function that will be run for each dataset normalization is applied to\n",
    "#   pull non-numeric columns before apply quantile normalization (bc each column needs to be a chip, and each row a probe)\n",
    "#   ** notice ** unlike qn and qn-target, tranpose is not required here!\n",
    "#   (source) https://github.com/jenniferfranks/FSQN/blob/master/vignettes/FSQNvignette.pdf\n",
    "\n",
    "apply_fsqn <- function(arg_samples, arg_target){\n",
    "    print(\"\")\n",
    "    print(\"  begin apply_fsqn\")\n",
    "\n",
    "    tmp_df <- data.frame(arg_samples)    # to make sure we make a copy of the df\n",
    "    \n",
    "  \n",
    "    print(\"    Preparing for the normalization call\")\n",
    "    samples_id_label <- arg_samples %>% \n",
    "        select(sample_id, label)\n",
    "    \n",
    "    tmp_df <- tmp_df %>% \n",
    "        select(-sample_id, -label)\n",
    "    \n",
    "    print(\"    (checking dimensions of arg_samples without sample_id and labels columns)\")\n",
    "    print(dim(tmp_df))\n",
    "\n",
    "\n",
    "    print(\"    (converting df to matrix)\")\n",
    "    matrix <- as.matrix(sapply(tmp_df, as.numeric))\n",
    "    rownames(matrix) <- samples_id_label$sample_id\n",
    "    \n",
    "    print(\"    (previewing matrix before normalization call)\")\n",
    "    print(head(matrix[,1:3], 2))\n",
    "    print(tail(matrix[,1:3], 2))\n",
    "    \n",
    "    # code to deal with the target\n",
    "    target_df <- data.frame(arg_target)\n",
    "    target_id_label <- arg_target %>% \n",
    "        select(sample_id, label)\n",
    "    target_df <- target_df %>% \n",
    "        select(-sample_id, -label)\n",
    "    print(\"    (arg_target - checking dimensions of without sample_id and labels columns)\")\n",
    "    print(dim(target_df)) \n",
    "    print(\"    (arg_target - converting df to matrix)\")\n",
    "    matrix_target <- as.matrix(sapply(target_df, as.numeric))\n",
    "    rownames(matrix_target) <- target_id_label$sample_id\n",
    "    print(\"    (arg_target - previewing matrix before normalization call)\")\n",
    "    print(head(matrix_target[,1:3], 2))\n",
    "    print(tail(matrix_target[,1:3], 2))\n",
    "    \n",
    "    # the actual normalization call\n",
    "    print(\"   Performing the actual normalization call\")\n",
    "    matrix_norm <- quantileNormalizeByFeature(matrix, matrix_target)\n",
    "\n",
    "    # *notice* at this point we do not care about the target anymore, just deal with the non-target\n",
    "    \n",
    "    print(\"    (previewing matrix after normalization call; now creating header for new matrix \")\n",
    "    colnames(matrix_norm) <- colnames(matrix)\n",
    "    rownames(matrix_norm) <- rownames(matrix)\n",
    "    print(head(matrix_norm[,1:3], 2))\n",
    "    print(tail(matrix_norm[,1:3], 2))\n",
    "    \n",
    "    print(\"    (converting matrix to df)\")\n",
    "    x_norm <- as.data.frame(matrix_norm)\n",
    "    \n",
    "    # put back non-numeric columns to df\n",
    "    print(\"   Recreating the original df with updated expression values post normalization call\")\n",
    "    \n",
    "    x_norm$sample_id <- rownames(x_norm)\n",
    "    \n",
    "    print(\"    (checking dimensions of x_normalized)\")\n",
    "    print(dim(x_norm))\n",
    "    \n",
    "    print(\"    (previewing x_norm)\")\n",
    "    print(head(x_norm[,1:3], 2))\n",
    "    print(tail(x_norm[,1:3], 2))\n",
    "\n",
    "    print(\"    (need to) perform an outer join with earlier df that contains label column\")\n",
    "    tmp_df <- merge(x=x_norm, y=samples_id_label, by=\"sample_id\", all=TRUE)\n",
    "\n",
    "    print(\"    (reorganize df column order)\")\n",
    "    updated_samples <- tmp_df %>% \n",
    "        select(sample_id, label, everything())\n",
    "    \n",
    "    print(\"  sort by label then by sample_id\")\n",
    "    updated_samples <- updated_samples %>%\n",
    "       group_by(label) %>%\n",
    "       arrange(sample_id, .by_group = TRUE)\n",
    "\n",
    "    print(\"    (checking dimensions of tranposed df)\")\n",
    "    print(dim(updated_samples))\n",
    "\n",
    "    print(\"    (previewing updated df)\")\n",
    "    print(head(updated_samples[,1:3], 2))\n",
    "    print(tail(updated_samples[,1:3], 2))\n",
    "    \n",
    "    print(\"    (comparing back to arg_samples)\")\n",
    "    print(dim(arg_samples))\n",
    "    print(head(arg_samples[,1:3], 2))\n",
    "    print(tail(arg_samples[,1:3], 2))\n",
    "    \n",
    "    \n",
    "    print(\"  end apply_fsqn, returning modified input\")\n",
    "    print(\"\")\n",
    "    \n",
    "    return(updated_samples)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function\n",
    "\n",
    "# (returns) if found then print the (rows=sample_id) and (cols=gene names) that are zero\n",
    "check_if_any_genes_zero <- function(arg_data, arg_debug_filename){\n",
    "    print(\"  begin check_if_any_genes_zero()\")\n",
    "\n",
    "    # remember that arg_data has first two cols as sample_id, label, then rest are genes; rows are each sample\n",
    "    \n",
    "    # work with a copy just in case and also assign row names as first column\n",
    "    tmp_df <- data.frame(arg_data)\n",
    "    \n",
    "    # assign row names as first column\n",
    "    rownames(tmp_df) <- tmp_df$sample_id\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"[DEBUG]---------------------------------[DEBUG]\")\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    ## working - checks all elements and prints out the location with zero value\n",
    "#     print(sprintf(\"  # rows: %s\", nrow(tmp_df)))\n",
    "#     print(sprintf(\"  # cols: %s\", ncol(tmp_df)))\n",
    "#     for (row in 1:nrow(tmp_df)){\n",
    "#         for (column in 1:ncol(tmp_df)){\n",
    "#             if (tmp_df[row, column] == 0){\n",
    "#                 cur_row_name = rownames(tmp_df)[row]\n",
    "#                 cur_col_name = colnames(tmp_df)[column]\n",
    "#                 print(sprintf('  + found zero @ (%s,%s): %s',\n",
    "#                               cur_row_name,\n",
    "#                               cur_col_name,\n",
    "#                               tmp_df[row, column])\n",
    "#                 )\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     # (for testing only) set all value of this gene equal to zero\n",
    "#     tmp_df$ENSG00000000419 <- 0\n",
    "    \n",
    "    ## working - checks for columns(=genes) where all values zero and prints out the name of gene    \n",
    "    for (column in 1:ncol(tmp_df)){\n",
    "        if (all(tmp_df[ ,column] == 0)){\n",
    "            cur_col_name = colnames(tmp_df)[column]\n",
    "            print(sprintf('  + found all zeroes in col @ %s', cur_col_name))\n",
    "            counter = counter + 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(sprintf('  + [Total genes found with all zeros] %s', counter))\n",
    "    \n",
    "#     # be sure that you want to save the snapshots of files, because each one is many GBs and takes up lots of space!\n",
    "#     print(sprintf('  + writing %s to file under results/debug/', arg_debug_filename))\n",
    "#     save_filename_w_path_debug = paste(PATH_TO_DEBUG, arg_debug_filename, \".tsv\", sep=\"\")\n",
    "#     write_tsv(arg_data, save_filename_w_path_debug)\n",
    "    \n",
    "    \n",
    "    print(\"[END_DEBUG]-------------------------[END_DEBUG]\")\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    print(\"  end check_if_any_genes_zero()\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  about to apply normalization function on -- 20% TCGA data for testing, with helper function too\")\n",
    "check_if_any_genes_zero(samples_tcga_test, \"notebook09b_tcga_test_before_fsqn\")\n",
    "normalized_samples_tcga_test <- apply_fsqn(samples_tcga_test, samples_tcga_train)\n",
    "check_if_any_genes_zero(normalized_samples_tcga_test, \"notebook09b_tcga_test_after_fsqn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  about to apply normalization function on -- 100% GTEx data for testing, with helper function too\")\n",
    "check_if_any_genes_zero(samples_gtex, \"notebook09b_gtex_test_before_fsqn\")\n",
    "normalized_samples_gtex <- apply_fsqn(samples_gtex, samples_tcga_train)\n",
    "check_if_any_genes_zero(normalized_samples_gtex, \"notebook09b_gtex_test_after_fsqn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da26725",
   "metadata": {},
   "source": [
    "## Combine 80% of TCGA and 20% of TCGA back into one dataset\n",
    "- *important to not sort before saving*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e382010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  combining train set (80% TCGA) and test set (20% TCGA)\")\n",
    "all_samples_tcga <- rbindlist(list(\n",
    "                                    samples_tcga_train, \n",
    "                                    normalized_samples_tcga_test\n",
    "                                    ))\n",
    "\n",
    "print(\"  checking dimensions of each individual and combined datasets\")\n",
    "print(\"   (100% TCGA samples)\")\n",
    "print(dim(all_samples_tcga))\n",
    "print(\"   (80%  TCGA samples)\")\n",
    "print(dim(samples_tcga_train))\n",
    "print(\"   (20%  TCGA samples)\")\n",
    "print(dim(normalized_samples_tcga_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5270e",
   "metadata": {},
   "source": [
    "## Save the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"  Saving the files \")\n",
    "\n",
    "# ---------------------- TCGA dataset ---------------------------\n",
    "\n",
    "save_filename_w_path_tcga = paste(\"data/preprocessing_combinations/\", save_filename_tcga, sep=\"\")\n",
    "\n",
    "sprintf(\"    writing tcga table to path -- %s\", save_filename_w_path_tcga)\n",
    "write_tsv(all_samples_tcga, save_filename_w_path_tcga)\n",
    "print(\"  tcga table saved-- \")\n",
    "\n",
    "# ---------------------- GTEx dataset ---------------------------\n",
    "\n",
    "save_filename_w_path_gtex = paste(\"data/preprocessing_combinations/\", save_filename_gtex, sep=\"\")\n",
    "\n",
    "sprintf(\"    writing gtex table to path -- %s\", save_filename_w_path_gtex)\n",
    "write_tsv(normalized_samples_gtex, save_filename_w_path_gtex)\n",
    "print(\"  gtex table saved-- \")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
